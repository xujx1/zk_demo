# zk_demo
zookeeper demo

paxos： http://www.cnblogs.com/endsock/p/3480093.html

zab协议：http://www.cnblogs.com/jian-xiao/p/5821675.html


现在通过一则故事来学习paxos的算法的流程(2阶段提交)，有2个Client(老板，老板之间是竞争关系)和3个Acceptor(政府官员)：

   现在需要对一项议题来进行paxos过程，议题是“A项目我要中标！”，这里的“我”指每个带着他的秘书Proposer的Client老板。
   Proposer当然听老板的话了，赶紧带着议题和现金去找Acceptor政府官员。
   作为政府官员，当然想谁给的钱多就把项目给谁。
   Proposer-1小姐带着现金同时找到了Acceptor-1~Acceptor-3官员，1与2号官员分别收取了10比特币，找到第3号官员时，没想到遭到了3号官员的鄙视，
   3号官员告诉她，Proposer-2给了11比特币。不过没关系，Proposer-1已经得到了1,2两个官员的认可，
   形成了多数派(如果没有形成多数派，Proposer-1会去银行提款在来找官员们给每人20比特币，这个过程一直重复每次+10比特币，直到多数派的形成)，
   满意的找老板复命去了，但是此时Proposer-2保镖找到了1,2号官员，分别给了他们11比特币，1,2号官员的态度立刻转变，
   都说Proposer-2的老板懂事，这下子Proposer-2放心了，搞定了3个官员，找老板复命去了，当然这个过程是第一阶段提交，只是官员们初步接受贿赂而已。
   故事中的比特币是编号，议题是value。

　　这个过程保证了在某一时刻，某一个proposer的议题会形成一个多数派进行初步支持；

 ===============华丽的分割线，第一阶段结束================

　　5.　现在进入第二阶段提交，现在proposer-1小姐使用分身术(多线程并发)分了3个自己分别去找3位官员，
    最先找到了1号官员签合同，遭到了1号官员的鄙视，1号官员告诉他proposer-2先生给了他11比特币，
    因为上一条规则的性质proposer-1小姐知道proposer-2第一阶段在她之后又形成了多数派(至少有2位官员的赃款被更新了);
    此时她赶紧去提款准备重新贿赂这3个官员(重新进入第一阶段)，每人20比特币。刚给1号官员20比特币， 1号官员很高兴初步接受了议题，
    还没来得及见到2,3号官员的时候，这时proposer-2先生也使用分身术分别找3位官员(注意这里是proposer-2的第二阶段)，
    被第1号官员拒绝了告诉他收到了20比特币，第2,3号官员顺利签了合同，这时2，3号官员记录client-2老板用了11比特币中标，
    因为形成了多数派，所以最终接受了Client2老板中标这个议题，对于proposer-2先生已经出色的完成了工作；
    这时proposer-1小姐找到了2号官员，官员告诉她合同已经签了，
    将合同给她看，proposer-1小姐是一个没有什么职业操守的聪明人，
    觉得跟Client1老板混没什么前途，所以将自己的议题修改为“Client2老板中标”，
    并且给了2号官员20比特币，这样形成了一个多数派。顺利的再次进入第二阶段。由于此时没有人竞争了，
    顺利的找3位官员签合同，3位官员看到议题与上次一次的合同是一致的，所以最终接受了，形成了多数派，proposer-1小姐跳槽到Client2老板的公司去了。

===============华丽的分割线，第二阶段结束===============

　　Paxos过程结束了，这样，一致性得到了保证，算法运行到最后所有的proposer都投“client2中标”所有的acceptor都接受这个议题，
    也就是说在最初的第二阶段，议题是先入为主的，谁先占了先机，后面的proposer在第一阶段就会学习到这个议题而修改自己本身的议题，
    因为这样没职业操守，才能让一致性得到保证，这就是paxos算法的一个过程。原来paxos算法里的角色都是这样的不靠谱，
    不过没关系，结果靠谱就可以了。该算法就是为了追求结果的一致性。




ZAB ( ZooKeeper Atomic Broadcast , ZooKeeper 原子消息广播协议）是zookeeper数据一致性的核心算法。

　　ZAB 协议并不像 Paxos 算法那样，是一种通用的分布式一致性算法，它是一种特别为 ZooKeeper 设计的崩溃可恢复的原子消息广播算法。

 

　　ZAB协议主要实现了：

　　1.使用一个单一的主进程来接收并处理客户端的所有事务请求，并采用 ZAB 的原子广播协议，将服务器数据的状态变更以事务 Proposal 的形式广播到所有的副本进程上去。

　　2.保证一个全局的变更序列被顺序应用。

　　　　ZooKeeper是一个树形结构，很多操作都要先检查才能确定能不能执行，比如P1的事务t1可能是创建节点“/a”，t2可能是创建节点“/a/aa”，只有先创建了父节点“/a”，
    才能创建子节点“/a/aa”。为了保证这一点，ZAB要保证同一个leader的发起的事务要按顺序被apply，
    同时还要保证只有先前的leader的所有事务都被apply之后，新选的leader才能在发起事务。

　　3.当前主进程出现异常情况的时候，依旧能够正常工作。

 

　　ZAB 协议的核心：定义了事务请求的处理方式。

　　所有事务请求必须由一个全局唯一的服务器来协调处理，这样的服务器被称为 Leader服务器，
    而余下的其他服务器则成为 Follower 服务器。 Leader 服务器负责将一个客户端事务请求转换成一个事务proposal（提议），
    并将该 Proposal分发给集群中所有的Follower服务器。之后 Leader 服务器需要等待所有Follower 服务器的反馈,
    一旦超过半数的Follower服务器进行了正确的反馈后，那么 Leader 就会再次向所有的 Follower服务器分发Commit消息，要求其将前一个proposal进行提交。

　　这种事务处理方式与2PC（两阶段提交协议）区别在于，两阶段提交协议的第二阶段中，需要等到所有参与者的"YES"回复才会提交事务，
    只要有一个参与者反馈为"NO"或者超时无反馈，都需要中断和回滚事务。

 

　　# ZAB协议介绍：

　　ZAB 协议包括两种基本的模式，分别是崩溃恢复和消息广播。

　　当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，
    ZAB 协议就会进入恢复模式并选举产生新的 Leader 服务器。当选举产生了新的Leader 服务器同时集群中已经有过半的机器与该 Leader 服务器完成了状态同步之后，
    ZAB 协议就会退出恢复模式。

　　当集群中已经有过半的 Follower 服务器完成了和 Leader 服务器的状态同步，那么整个服务框架就可以进入消息广播模式了。
    当一台同样遵守 ZAB 协议的服务器启动后加入到集群中时，如果此时集群中已经存在一个 Leader 服务器在负责进行消息广播 ，
     那么新加人的服务器就会自觉地进人数据恢复模式：找到 Leader 所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。

　　下面重点讲解崩溃回复和消息广播的过程。

　　# 消息广播

　　ZAB 协议的消息广播过程使用的是一个原子广播协议，类似于一个二阶段提交过程。针对客户端的事务请求，
 Leader 服务器会为其生成对应的事务 Proposal ,并将其发送给集群中其余所有的机器，然后再分別收集各自的选票，最后进行事务提交。

 

　　

　　在 ZAB 协议的二阶段提交过程中，移除了中断逻辑，所有的 Follower 服务器要么正常反馈 Leader 提出的事务 Proposal ,要么就抛弃Leader 服务器。
    同时， ZAB 协议将二阶段提交中的中断逻辑移除意味着我们可以在过半的 Follower 服务器已经反馈 Ack 之后就开始提交事务 Proposal 了，
    而不需要等待集群中所有的 Follower 服务器都反馈响应。这种简化了的二阶段提交模型无法处理 Leader 服务器崩溃退出而带来的数据不一致问题，
    此时采用崩溃恢复模式来解决这个问题。

　　在整个消息广播过程中， Leader 服务器会为每个事务请求生成对应的 Proposal来进行广播，并且在广播事务 Proposal 之前，
    Leader 服务器会首先为这个事务 Proposal 分配一个全局单调递增的唯一事务ID (即 ZXID )。

　　Leader 服务器会为每一个 Follower 服务器都各自分配一个单独的队列，然后将需要广播的事务 Proposal 依次放入这些队列中去，
    并且根据 FIFO策略进行消息发送。每一个 Follower 服务器在接收到这个事务 Proposal 之后，都会首先将其以事务日志的形式写入到本地磁盘中去，
    并且在成功写入后反馈给 Leader 服务器一个 Ack 响应。当 Leader 服务器接收到超过半数 Follower 的 Ack 响应后，
    就会广播一个Commit 消息给所有的 Follower 服务器以通知其进行事务提交，同时 Leader 自身也会完成对事务的提交。

　　# 崩溃恢复

　　Leader 服务器出现崩溃，或者说由于网络原因导致 Leader 服务器失去了与过半 Follower 的联系，那么就会进入崩溃恢复模式。
    Leader 选举算法不仅仅需要让 Leader自己知道其自身已经被选举为 Leader ,同时还需要让集群中的所有其他机器也能够快速地感知到选举产生的新的 Leader 服务器。

 　　ZAB 协议规定了如果一个事务 Proposal 在一台机器上被处理成功，那么应该在所有的机器上都被处理成功，哪怕机器出现故障崩溃。 

 　　下面介绍两种崩溃恢复中的场景和zab协议需要保证的特性：

　　 1.ZAB 协议需要确保那些已经在 Leader 服务器上提交的事务最终被所有服务器都提交

　　假设一个事务在 Leader 服务器上被提交了，并且已经得到过半 Follower 服务器的Ack 反馈，
    但是在它将 Commit 消息发送给所有 Follower 机器之前， Leader 服务器挂了，针对这种情况， 
    ZAB 协议就需要确保该事务最终能够在所有的服务器上都被提交成功，否则将出现不一致。

 　　2.ZAB协议需要确保丢弃那些只在 Leader 服务器上被提出的事务

　　假设初始的 Leader 服务器 在提出了一个事务之后就崩溃退出了，导致集群中的其他服务器都没有收到这个事务，
    当该服务器恢复过来再次加入到集群中的时候 ，ZAB协议需要确保丢弃这个事务。

 

　　针对以上两点需求，zab协议需要设计的选举算法应该满足：确保提交已经被 Leader 提交的事务 Proposal，同时丢弃已经被跳过的事务 Proposal 。

　　如果让 Leader 选举算法能够保证新选举出来的 Leader 服务器拥有集群中所有机器最高编号（即 ZXID 最大）的事务 Proposal,
    那么就可以保证这个新选举出来的 Leader —定具有所有已经提交的提案。同时，如果让具有最高编号事务 Proposal 的机器来成为 Leader, 
    就可以省去 Leader 服务器检查 Proposal 的提交和丢弃工作的这一步操作。

　　# 数据同步

　　Leader 服务器会为每一个 Follower 服务器都准备一个队列，
    并将那些没有被各 Follower 服务器同步的事务以 Proposal 消息的形式逐个发送给 Follower 服务器，
    并在每一个 Proposal 消息后面紧接着再发送一个 Commit 消息，以表示该事务已经被提交。
    等到 Follower 服务器将所有其尚未同步的事务 Proposal 都从 Leader 服务器上同步过来并成功应用到本地数据库中后，
    Leader 服务器就会将该 Follower 服务器加入到真正的可用 Follower 列表中，并开始之后的其他流程。

　　下面来看 ZAB 协议是如何处理那些需要被丢弃的事务 Proposal 的。
    在 ZAB 协议的事务编号 ZXID 设计中， ZXID 是一个 64 位的数字，低 32 位可以看作是一个简单的单调递增的计数器，
    针对客户端的每一个事务请求， Leader 服务器在产生一个新的事务 Proposal 的时候，都会对该计数器进行加1操作；
    高 32 位代表了 Leader 周期 epoch 的编号，每当选举产生一个新的 Leader 服务器，
    就会从这个 Leader 服务器上取出其本地日志中最大事务 Proposal 的 ZXID ,并从该 ZXID 中解析出对应的 epoch 值，
    然后再对其进行加1操作，之后就会以此编号作为新的 epoch, 并将低 32 位置0来开始生成新的 ZXID 。

　　基于这样的策略，当一个包含了上一个 Leader 周期中尚未提交过的事务 Proposal的服务器启动加入到集群中，
   发现此时集群中已经存在leader，将自身以Follower 角色连接上 Leader 服务器之后，
   Leader 服务器会根据自己服务器上最后被提交的 Proposal来和 Follower 服务器的 Proposal进行比对，
   发现follower中有上一个leader周期的事务Proposal时，Leader 会要求 Follower 进行一个回退操作——回退到一个确实已经被集群中过半机器提交的最新的事务 Proposal 。

 